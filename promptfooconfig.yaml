prompts: prompt.txt
providers: 
### OpenAI
  - openai:gpt-3.5-turbo-0125:
      id: gpt-3.5-turbo
      config:
        apiKey: 
        temperature: 0
  - openai:gpt-4-0125-preview:
      id: gpt-4-turbo
      config:
        apiKey: 
        temperature: 0
  - openai:gpt-4:
      id: gpt-4
      config:
        apiKey: 
        temperature: 0
### Anthropic
  - webhook:https://llm-proxy.babel.run/claude:
      id: claude3-Opus
      config:
        apiKey: 
        modelName: claude-3-opus-20240229
  - webhook:https://llm-proxy.babel.run/claude:
      id: claude3-Sonnet
      config:
        apiKey: 
        modelName: claude-3-sonnet-20240229
### Cohere
  - cohere:command:
      id: cohere
      config:
        apiKey: 
        temperature: 0
        max_tokens: 3000
### Mistral
  - mistral:mistral-large-latest:
      id: mistral
      config:
        apiKey: 
        temperature: 0
        max_tokens: 4096
### Google
  - google:gemini-pro:
      id: gemini-pro-1.0
      config:
        apiKey: 
        temperature: 0
        maxOutputTokens: 4096
### Minimax
  - webhook:https://llm-proxy.babel.run/minimax:
      id: minimax
      config:
        apiKey: 
        groupId: 
### Moonshot
  - webhook:https://llm-proxy.babel.run/moonshot:
      id: moonshot
      config:
        apiKey: 
### ZhiPu
  - webhook:https://llm-proxy.babel.run/chatglm:
      id: chatglm
      config:
        apiKey: 
### Baichuan
  - webhook:https://llm-proxy.babel.run/baichuan:
      id: baichuan2
      config:
        apiKey: 
        secretKey: 
### Baidu
  - webhook:https://llm-proxy.babel.run/baidu-erniebot4:
      id: baidu
      config:
        apiKey: 
        secretKey: 
### Alibaba
  - webhook:https://llm-proxy.babel.run/aliqwen:
      id: aliqwen
      config:
        apiKey: 
### Replicate
  # - replicate:meta/llama-2-70b-chat:35042c9a33ac8fd5e29e27fb3197f33aa483f72c2ce3b0b9d201155c7fd2a287:
  #     id: llama2
  #     config:
  #       apiKey: 
  #       temperature: 0.01
  #       max_new_tokens: 4096
  # - replicate:01-ai/yi-34b-chat:914692bbe8a8e2b91a4e44203e70d170c9c5ccc1359b283c84b0ec8d47819a46:
  #     id: Yi-34b-chat
  #     config:
  #       apiKey: 
  #       temperature: 0.01
  #       max_new_tokens: 4096
### Others
  # - webhook:https://llm-proxy.babel.run/sensenova:
  #     id: sensenova
  #     config:
  #       apiKey: 
  #       secretKey: 
  # - webhook:https://llm-proxy.babel.run/hunyuan:
  #     id: hunyuan
  #     config:
  #       app_id: 1253923140
  #       secret_id: 
  #       secret_key: 
defaultTest:
  options:
    postprocess: |
      output = output.replace('---', '').trim();
      return output;
tests:
  - testcases/001_requirement_check_config.yaml
  - testcases/002_code_completion_config.yaml
  - testcases/003_context_code_fix_config.yaml
  - testcases/004_sed_command_config.yaml
  - testcases/005_babel_elements_config.yaml
  - testcases/006_reading_comprehension_config.yaml
  - testcases/007_find_ball_config.yaml
  - testcases/008_email_assistant_config.yaml
  - testcases/009_customer_service_config.yaml
  - testcases/010_trip_plan_config.yaml
  - testcases/011_tool_using_config.yaml
  - testcases/012_linux_terminal_config.yaml
  - testcases/013_conversation_sanitizer_config.yaml
  - testcases/014_jailbreak_config.yaml
  - testcases/015_simple_mahjong_config.yaml